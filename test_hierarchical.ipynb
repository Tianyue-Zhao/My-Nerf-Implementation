{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def cumprod_exclusive(\n",
    "  tensor: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "  r\"\"\"\n",
    "  (Courtesy of https://github.com/krrish94/nerf-pytorch)\n",
    "\n",
    "  Mimick functionality of tf.math.cumprod(..., exclusive=True), as it isn't available in PyTorch.\n",
    "\n",
    "  Args:\n",
    "  tensor (torch.Tensor): Tensor whose cumprod (cumulative product, see `torch.cumprod`) along dim=-1\n",
    "    is to be computed.\n",
    "  Returns:\n",
    "  cumprod (torch.Tensor): cumprod of Tensor along dim=-1, mimiciking the functionality of\n",
    "    tf.math.cumprod(..., exclusive=True) (see `tf.math.cumprod` for details).\n",
    "  \"\"\"\n",
    "\n",
    "  # Compute regular cumprod first (this is equivalent to `tf.math.cumprod(..., exclusive=False)`).\n",
    "  cumprod = torch.cumprod(tensor, 1)\n",
    "  # \"Roll\" the elements along dimension 'dim' by 1 element.\n",
    "  cumprod = torch.roll(cumprod, 1, 1)\n",
    "  # Replace the first element by \"1\" as this is what tf.cumprod(..., exclusive=True) does.\n",
    "  cumprod[..., 0] = 1.\n",
    "  \n",
    "  return cumprod\n",
    "\n",
    "def sample_points_weighted(rays, sigma_value, distances, num_samples, fine_samples):\n",
    "    num_total = num_samples + fine_samples\n",
    "    points = rays[:, None, :3]\n",
    "    points = torch.tensor(points, device = sigma_value.device, dtype = torch.float32)\n",
    "    directions = rays[:, None, 3:]\n",
    "    directions = torch.tensor(directions, device = sigma_value.device, dtype = torch.float32)\n",
    "    distances = distances[:, :]\n",
    "    interval_lengths = distances[:, 1:] - distances[:, :-1]\n",
    "\n",
    "    # Translate sigma to weights\n",
    "    sigma_value = torch.reshape(sigma_value, (-1, num_samples))\n",
    "    interval_lengths = torch.cat([interval_lengths,\\\n",
    "        1e9 * torch.ones((interval_lengths.shape[0], 1), device = interval_lengths.device)], dim = 1)\n",
    "    alpha = 1 - torch.exp(-sigma_value * interval_lengths * 100) # Each point approximates values for the interval after it\n",
    "    weights = alpha * cumprod_exclusive(1 - alpha + 1e-9)\n",
    "    print(weights[0, :])\n",
    "\n",
    "    # Sample points to translate from the weight distribution\n",
    "    weights = weights[:, 1:-1] + 1e-5\n",
    "    pdf = weights / torch.sum(weights, dim = 1, keepdim = True)\n",
    "    cdf = torch.cumsum(pdf, dim = 1)\n",
    "    cdf = torch.cat([torch.zeros_like(cdf[:, :1]), cdf], dim = 1)\n",
    "    samples = torch.rand((cdf.shape[0], fine_samples), device = sigma_value.device)\n",
    "    samples = samples.contiguous()\n",
    "    indices = torch.searchsorted(cdf, samples, right = True) # Rays x fine_samples\n",
    "    indices = torch.min((num_samples - 2) * torch.ones_like(indices), indices)\n",
    "    if(torch.min(indices) < 1):\n",
    "        print(\"At most 0 somehow\")\n",
    "        print(torch.min(indices))\n",
    "        print(cdf.shape)\n",
    "        exit()\n",
    "\n",
    "    # Sample on distribution\n",
    "    new_distances = 0.5 * (distances[:, 1:] + distances[:, :-1]) # Taking the midpoints according to the original code\n",
    "    interval_lengths = new_distances[:, 1:] - new_distances[:, :-1] # The lengths of the intervals between points\n",
    "    near_distances = torch.gather(new_distances, 1, indices - 1) # The near distance of the interval each selected point is in\n",
    "    interval_lengths = torch.gather(interval_lengths, 1, indices - 1)\n",
    "    probability_interval = torch.gather(pdf, 1, indices - 1)\n",
    "    probability_start = torch.gather(cdf, 1, indices - 1)\n",
    "    new_distances = near_distances + (samples - probability_start) * interval_lengths / probability_interval\n",
    "\n",
    "    # Calculate points and merge\n",
    "    distances = torch.cat([distances, new_distances], dim = 1)\n",
    "    distances, sort_indices = torch.sort(distances, dim = 1)\n",
    "    points = points + distances[:, :, None] * directions\n",
    "    points = points.reshape((-1, 3))\n",
    "    directions = torch.cat([directions] * num_total, dim = 1)\n",
    "    directions = directions.reshape((-1, 3))\n",
    "    return points, directions, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "rays = [[1, 1, 1, 1, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 0],\n",
    "        [1, 1, 1, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1],\n",
    "        [1, 2, 2, 0, 1, 0],\n",
    "        [1, 2, 2, 0, 1, 0],\n",
    "        [1, 2, 2, 0, 1, 0]]\n",
    "\n",
    "num_samples = 6\n",
    "fine_samples = 10\n",
    "sigma_value = [0.001, 0.001, 0.01, 0.8, 0.01, 0.01]\n",
    "distances = [0.1, 0.2, 0.29, 0.38, 0.48, 0.57]\n",
    "sigma_value = torch.tensor(sigma_value)\n",
    "sigma_value = torch.stack([sigma_value] * len(rays), dim = 0)\n",
    "distances = torch.tensor(distances)\n",
    "distances = torch.stack([distances] * len(rays), dim = 0)\n",
    "rgb_value = torch.zeros((len(rays), num_samples, 3))\n",
    "rays = np.asarray(rays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9502e-03, 8.8705e-03, 8.4449e-02, 8.9643e-01, 2.5891e-05, 2.7492e-04])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4b02e5070>]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points, directions, all_distances = sample_points_weighted(rays, sigma_value, distances, num_samples, fine_samples)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(distances.numpy()[0, :], torch.ones(num_samples), 'b-o')\n",
    "ax.plot(all_distances.numpy()[0, :], torch.zeros(num_samples + fine_samples), 'r-o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ba1072ec1f3e62d1a3b5a728a0f2304e60198da2eb6e323bf2a159a982a317e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
